#include  UniNDP/configs/UniNDP_baseline_NDP.cfg

# ------------------- for NDP-HBM DRAM access -------------------
# From QC: From wikipedia: HBM memory bus is very wide in comparison to other DRAM memories such as DDR4 or GDDR5. An HBM stack of four DRAM dies (4‑Hi) has two 128‑bit channels per die for a total of 8 channels and a width of 1024 bits in total. A graphics card/GPU with four 4‑Hi HBM stacks would therefore have a memory bus with a width of 4096 bits. In comparison, the bus width of GDDR memories is 32 bits, with 16 channels for a graphics card with a 512‑bit memory interface.[13] HBM supports up to 4 GB per package.

# From QC: This config is for 1 HBM stack with 8 channel * 128-bit, 16 bank per channel
[perf_model/dram/ddr]
num_banks=16 # banks per rank
num_bank_groups=4
num_ranks=1
rank_offset=6 # From QC: ?
num_channels=16 # From QC: Actually, it's 8 channels per stack, but the channel number is doubled to compensate for cutting the data bus width in half.
data_bus_width=512 # From QC: Each channel has a 128-bit data interface that provides 32GB/s bandwidth. Was 1024, changed to 256 because of cacheline 512 bit and ddr
dram_speed=2000
dram_page_size=16384 # From QC: Typical HBM page size, 2KB = 16384 bits
open_page_mapping="true"
column_offset=0
randomize_address="false"
randomize_offset=0
column_bits_shift=14 # From QC: ignored, this parameter is useful only open_page_mapping = false
bank_keep_open=120 # From QC: ?
constant_time_policy=false
selective_constant_time_policy=false
open_row_policy=true
bank_open_delay=15 # From QC: nRCDR in ramulator is 6, but some material says it's around 15
bank_close_delay=15 # From QC: nRCDW in ramulator is 6, but some material says it's around 15
access_cost=15 # From QC: Device access time (tCAS)
intercommand_delay=5
intercommand_delay_long=6.2 
intercommand_delay_short=4.2 # From QC: tCCDs
controller_delay=20 # From QC: ? important
refresh_interval=0
refresh_length=0